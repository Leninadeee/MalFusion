{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c4f2565-16e3-41c7-91cf-59afe105d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reu/miniconda3/envs/static/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy majority baseline accuracy: 0.5118708452041786\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9850    0.9759    0.9804       539\n",
      "           1     0.9750    0.9844    0.9797       514\n",
      "\n",
      "    accuracy                         0.9801      1053\n",
      "   macro avg     0.9800    0.9802    0.9800      1053\n",
      "weighted avg     0.9801    0.9801    0.9801      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[526  13]\n",
      " [  8 506]]\n",
      "\n",
      "=== Linear SVM ===\n",
      "Accuracy: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9617    0.9314    0.9463       539\n",
      "           1     0.9303    0.9611    0.9455       514\n",
      "\n",
      "    accuracy                         0.9459      1053\n",
      "   macro avg     0.9460    0.9462    0.9459      1053\n",
      "weighted avg     0.9464    0.9459    0.9459      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[502  37]\n",
      " [ 20 494]]\n",
      "\n",
      "=== AdaBoost ===\n",
      "Accuracy: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9757    0.9685    0.9721       539\n",
      "           1     0.9672    0.9747    0.9709       514\n",
      "\n",
      "    accuracy                         0.9715      1053\n",
      "   macro avg     0.9714    0.9716    0.9715      1053\n",
      "weighted avg     0.9715    0.9715    0.9715      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[522  17]\n",
      " [ 13 501]]\n",
      "\n",
      "=== Prediction agreement on test set ===\n",
      "RF vs SVM : 0.9601139601139601\n",
      "RF vs Ada : 0.9895536562203229\n",
      "SVM vs Ada: 0.9686609686609686\n",
      "\n",
      "=== Top features per model ===\n",
      "Random Forest:\n",
      "\n",
      "Top features:\n",
      "OP::mov                        0.0766\n",
      "OP::push                       0.0621\n",
      "OP::ret                        0.0564\n",
      "OP::add                        0.0527\n",
      "OP::nop                        0.0392\n",
      "OP::lea                        0.0362\n",
      "OP::movzx                      0.0361\n",
      "OP::jnz                        0.0354\n",
      "OP::jmp                        0.0319\n",
      "OP::jz                         0.0314\n",
      "OP::pushad                     0.0310\n",
      "OP::sub                        0.0309\n",
      "OP::imul                       0.0291\n",
      "OP::call                       0.0280\n",
      "OP::popad                      0.0264\n",
      "OP::cmp                        0.0245\n",
      "OP::xchg                       0.0243\n",
      "OP::pop                        0.0237\n",
      "OP::inc                        0.0234\n",
      "OP::adc                        0.0178\n",
      "\n",
      "Linear SVM:\n",
      "\n",
      "Top features:\n",
      "OP::jz                         +6.0531\n",
      "OP::push                       -5.6972\n",
      "OP::lea                        +5.4325\n",
      "OP::jmp                        +5.2358\n",
      "OP::test                       +5.0908\n",
      "OP::mov                        -3.9322\n",
      "OP::sbb                        -3.8115\n",
      "OP::cmp                        -3.5914\n",
      "OP::xor                        -3.2287\n",
      "OP::call                       +2.7979\n",
      "OP::add                        -2.7303\n",
      "OP::inc                        +2.6941\n",
      "OP::and                        -2.5711\n",
      "OP::ja                         +2.4695\n",
      "OP::fldcw                      +2.2505\n",
      "OP::adc                        -1.9305\n",
      "OP::or                         -1.9130\n",
      "OP::movsb.rep                  +1.6893\n",
      "OP::sar                        +1.6658\n",
      "OP::shr                        +1.5677\n",
      "\n",
      "AdaBoost:\n",
      "\n",
      "Top features:\n",
      "OP::push                       0.1324\n",
      "OP::mov                        0.1087\n",
      "OP::jmp                        0.0765\n",
      "OP::cmp                        0.0683\n",
      "OP::test                       0.0454\n",
      "OP::jbe                        0.0415\n",
      "OP::movzx                      0.0383\n",
      "OP::shr                        0.0357\n",
      "OP::call                       0.0353\n",
      "OP::sub                        0.0352\n",
      "OP::jnz                        0.0316\n",
      "OP::inc                        0.0295\n",
      "OP::sbb                        0.0272\n",
      "OP::jz                         0.0267\n",
      "OP::ret                        0.0250\n",
      "OP::xor                        0.0243\n",
      "OP::imul                       0.0227\n",
      "OP::pop                        0.0221\n",
      "OP::movsw                      0.0210\n",
      "OP::jns                        0.0195\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "def load_data(malware_csv: str, ransomware_csv: str):\n",
    "    mw = pd.read_csv(malware_csv)\n",
    "    rw = pd.read_csv(ransomware_csv)\n",
    "    mw['label'] = 0\n",
    "    rw['label'] = 1\n",
    "    df = pd.concat([mw, rw], ignore_index=True)\n",
    "    df['opcodes'] = df['opcodes'].fillna('').astype(str)\n",
    "    #df['api_calls'] = df['api_calls'].fillna('').astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def vectorise(df, ngram_min: int, ngram_max: int, max_features: int):\n",
    "    opcode_vect = TfidfVectorizer(\n",
    "        tokenizer=lambda s: s.split(),\n",
    "        ngram_range=(ngram_min, ngram_max),\n",
    "        max_features=max_features,\n",
    "    )\n",
    "    op_mat = opcode_vect.fit_transform(df['opcodes'])\n",
    "    #api_mat = api_vect.fit_transform(df['api_calls'])\n",
    "    X = hstack([op_mat], format='csr')\n",
    "    feature_names = (\n",
    "        [f\"OP::{t}\" for t in opcode_vect.get_feature_names_out()]\n",
    "    )\n",
    "    return X, df['label'].values, feature_names\n",
    "\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, n_jobs=-1\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    svm = SVC(\n",
    "        kernel='linear', probability=True\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    ada = AdaBoostClassifier(\n",
    "        n_estimators=100\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    return rf, svm, ada\n",
    "\n",
    "\n",
    "def evaluate(name, clf, X_test, y_test):\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, pred):.4f}\")\n",
    "    print(classification_report(y_test, pred, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def top_features(clf, feature_names, top_k=20):\n",
    "    print(\"\\nTop features:\")\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        idx = np.argsort(clf.feature_importances_)[::-1][:top_k]\n",
    "        for i in idx:\n",
    "            print(f\"{feature_names[i]:30s} {clf.feature_importances_[i]:.4f}\")\n",
    "    elif hasattr(clf, \"coef_\"):\n",
    "        coefs = clf.coef_\n",
    "        if hasattr(coefs, \"toarray\"):\n",
    "            coefs = coefs.toarray().ravel()\n",
    "        else:\n",
    "            coefs = np.asarray(coefs).ravel()\n",
    "        idx = np.argsort(np.abs(coefs))[::-1][:top_k]\n",
    "        for i in idx:\n",
    "            print(f\"{feature_names[i]:30s} {coefs[i]:+.4f}\")\n",
    "    else:\n",
    "        print(\"Feature importance not available for this estimator.\")\n",
    "\n",
    "\n",
    "def agreement(a, b):\n",
    "    return np.mean(a == b)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- Data & features -------------------------------------------------\n",
    "    df = load_data(\"../mw_ghidra_truncated.csv\", \"../rw_ghidra_truncated.csv\")\n",
    "    X, y, feat_names = vectorise(df, 1, 1, 5000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Baseline --------------------------------------------------------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\").fit(X_train, y_train)\n",
    "    print(\"Dummy majority baseline accuracy:\", dummy.score(X_test, y_test))\n",
    "\n",
    "    # --- Train models ----------------------------------------------------\n",
    "    rf, svm, ada = train_models(X_train, y_train)\n",
    "\n",
    "    # --- Evaluate --------------------------------------------------------\n",
    "    rf_pred = evaluate(\"Random Forest\", rf, X_test, y_test)\n",
    "    svm_pred = evaluate(\"Linear SVM\", svm, X_test, y_test)\n",
    "    ada_pred = evaluate(\"AdaBoost\", ada, X_test, y_test)\n",
    "\n",
    "    # --- Agreement -------------------------------------------------------\n",
    "    print(\"\\n=== Prediction agreement on test set ===\")\n",
    "    print(\"RF vs SVM :\", agreement(rf_pred, svm_pred))\n",
    "    print(\"RF vs Ada :\", agreement(rf_pred, ada_pred))\n",
    "    print(\"SVM vs Ada:\", agreement(svm_pred, ada_pred))\n",
    "\n",
    "\n",
    "    # --- Top features ----------------------------------------------------\n",
    "    print(\"\\n=== Top features per model ===\")\n",
    "    print(\"Random Forest:\")\n",
    "    top_features(rf, feat_names)\n",
    "    print(\"\\nLinear SVM:\")\n",
    "    top_features(svm, feat_names)\n",
    "    print(\"\\nAdaBoost:\")\n",
    "    top_features(ada, feat_names)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84406786-ccad-4e5b-946e-23b67bd606fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reu/miniconda3/envs/static/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy majority baseline accuracy: 0.5118708452041786\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9907    0.9870    0.9888       539\n",
      "           1     0.9864    0.9903    0.9883       514\n",
      "\n",
      "    accuracy                         0.9886      1053\n",
      "   macro avg     0.9886    0.9886    0.9886      1053\n",
      "weighted avg     0.9886    0.9886    0.9886      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[532   7]\n",
      " [  5 509]]\n",
      "\n",
      "=== Linear SVM ===\n",
      "Accuracy: 0.9582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9365    0.9852    0.9602       539\n",
      "           1     0.9835    0.9300    0.9560       514\n",
      "\n",
      "    accuracy                         0.9582      1053\n",
      "   macro avg     0.9600    0.9576    0.9581      1053\n",
      "weighted avg     0.9595    0.9582    0.9582      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[531   8]\n",
      " [ 36 478]]\n",
      "\n",
      "=== AdaBoost ===\n",
      "Accuracy: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    0.9796    0.9769       539\n",
      "           1     0.9785    0.9728    0.9756       514\n",
      "\n",
      "    accuracy                         0.9763      1053\n",
      "   macro avg     0.9763    0.9762    0.9762      1053\n",
      "weighted avg     0.9763    0.9763    0.9763      1053\n",
      "\n",
      "Confusion matrix:\n",
      " [[528  11]\n",
      " [ 14 500]]\n",
      "\n",
      "=== Prediction agreement on test set ===\n",
      "RF vs SVM : 0.9639126305792972\n",
      "RF vs Ada : 0.9819563152896487\n",
      "SVM vs Ada: 0.9591642924976258\n",
      "\n",
      "=== Top features per model ===\n",
      "Random Forest:\n",
      "\n",
      "Top features:\n",
      "API:: ldrgetprocedureaddress   0.0853\n",
      "API:: ldrgetdllhandle          0.0849\n",
      "API:: findfirstfileexw         0.0615\n",
      "API:: ntcreatefile             0.0485\n",
      "API:: ntwritefile              0.0477\n",
      "API:: createprocessinternalw   0.0322\n",
      "API:: ntclose                  0.0308\n",
      "API:: ntreadfile               0.0300\n",
      "API::ntallocatevirtualmemory   0.0296\n",
      "API:: __exception__            0.0274\n",
      "API:: setfilepointer           0.0240\n",
      "API:: ntallocatevirtualmemory  0.0230\n",
      "API:: ldrloaddll               0.0210\n",
      "API:: getsystemtimeasfiletime  0.0205\n",
      "API:: ntterminateprocess       0.0204\n",
      "API::ldrloaddll                0.0202\n",
      "API:: regsetvalueexa           0.0182\n",
      "API:: regopenkeyexw            0.0179\n",
      "API:: ntopenprocess            0.0154\n",
      "API:: getsystemmetrics         0.0149\n",
      "\n",
      "Linear SVM:\n",
      "\n",
      "Top features:\n",
      "API:: ntterminateprocess       +3.9927\n",
      "API:: setunhandledexceptionfilter +3.8955\n",
      "API:: ntquerydirectoryfile     +3.6299\n",
      "API:: getsystemdirectorya      +3.0949\n",
      "API:: ntquerykey               +2.7816\n",
      "API:: ntqueryinformationfile   -2.6780\n",
      "API::ldrgetdllhandle           -2.6496\n",
      "API:: ntwritefile              +2.5422\n",
      "API::ntclose                   +2.4932\n",
      "API:: process32nextw           +2.2869\n",
      "API:: findresourcea            -2.2698\n",
      "API::regopenkeyexw             -2.1644\n",
      "API:: seterrormode             -2.1253\n",
      "API:: openscmanagera           +2.1136\n",
      "API:: ntquerysysteminformation +2.0759\n",
      "API:: thread32next             +2.0473\n",
      "API:: ntreadfile               +2.0464\n",
      "API:: createprocessinternalw   +2.0442\n",
      "API::ntopenkey                 +1.9732\n",
      "API:: loadstringa              +1.8713\n",
      "\n",
      "AdaBoost:\n",
      "\n",
      "Top features:\n",
      "API:: ldrgetprocedureaddress   0.0882\n",
      "API:: setunhandledexceptionfilter 0.0692\n",
      "API:: ntcreatefile             0.0660\n",
      "API:: createprocessinternalw   0.0586\n",
      "API:: regsetvalueexa           0.0513\n",
      "API:: getsystemdirectorya      0.0478\n",
      "API:: ldrgetdllhandle          0.0474\n",
      "API:: findfirstfileexw         0.0465\n",
      "API:: ntreadfile               0.0395\n",
      "API:: __exception__            0.0371\n",
      "API:: enumwindows              0.0326\n",
      "API:: ntwritefile              0.0295\n",
      "API::ldrgetdllhandle           0.0292\n",
      "API:: setfilepointer           0.0260\n",
      "API:: ntqueryvaluekey          0.0227\n",
      "API:: createthread             0.0215\n",
      "API:: getfiletype              0.0203\n",
      "API::ldrloaddll                0.0202\n",
      "API:: getsystemwindowsdirectoryw 0.0201\n",
      "API:: createactctxw            0.0187\n"
     ]
    }
   ],
   "source": [
    "def load_data(malware_csv: str, ransomware_csv: str):\n",
    "    mw = pd.read_csv(malware_csv)\n",
    "    rw = pd.read_csv(ransomware_csv)\n",
    "    mw['label'] = 0\n",
    "    rw['label'] = 1\n",
    "    df = pd.concat([mw, rw], ignore_index=True)\n",
    "    df['opcodes'] = df['opcodes'].fillna('').astype(str)\n",
    "    df['api_calls'] = df['api_calls'].fillna('').astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def vectorise(df, ngram_min: int, ngram_max: int, max_features: int):\n",
    "    #opcode_vect = TfidfVectorizer(\n",
    "    #    tokenizer=lambda s: s.split(),\n",
    "    #    ngram_range=(ngram_min, ngram_max),\n",
    "    #    max_features=max_features,\n",
    "    #)\n",
    "    api_vect = TfidfVectorizer(\n",
    "        tokenizer=lambda s: [tok for tok in s.split(';') if tok],\n",
    "        ngram_range=(ngram_min, ngram_max),\n",
    "        max_features=max_features,\n",
    "    )\n",
    "    #op_mat = opcode_vect.fit_transform(df['opcodes'])\n",
    "    api_mat = api_vect.fit_transform(df['api_calls'])\n",
    "    X = hstack([api_mat], format='csr')\n",
    "    feature_names = (\n",
    "        [f\"API::{t}\" for t in api_vect.get_feature_names_out()]\n",
    "    )\n",
    "    return X, df['label'].values, feature_names\n",
    "\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, n_jobs=-1, class_weight='balanced'\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    svm = SVC(\n",
    "        kernel='linear', probability=True, class_weight='balanced'\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    ada = AdaBoostClassifier(\n",
    "        n_estimators=100\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    return rf, svm, ada\n",
    "\n",
    "\n",
    "def evaluate(name, clf, X_test, y_test):\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, pred):.4f}\")\n",
    "    print(classification_report(y_test, pred, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def top_features(clf, feature_names, top_k=20):\n",
    "    print(\"\\nTop features:\")\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        idx = np.argsort(clf.feature_importances_)[::-1][:top_k]\n",
    "        for i in idx:\n",
    "            print(f\"{feature_names[i]:30s} {clf.feature_importances_[i]:.4f}\")\n",
    "    elif hasattr(clf, \"coef_\"):\n",
    "        coefs = clf.coef_\n",
    "        if hasattr(coefs, \"toarray\"):\n",
    "            coefs = coefs.toarray().ravel()\n",
    "        else:\n",
    "            coefs = np.asarray(coefs).ravel()\n",
    "        idx = np.argsort(np.abs(coefs))[::-1][:top_k]\n",
    "        for i in idx:\n",
    "            print(f\"{feature_names[i]:30s} {coefs[i]:+.4f}\")\n",
    "    else:\n",
    "        print(\"Feature importance not available for this estimator.\")\n",
    "\n",
    "\n",
    "def agreement(a, b):\n",
    "    return np.mean(a == b)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- Data & features -------------------------------------------------\n",
    "    df = load_data(\"../mw_ghidra_truncated.csv\", \"../rw_ghidra_truncated.csv\")\n",
    "    X, y, feat_names = vectorise(df, 1, 1, 5000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Baseline --------------------------------------------------------\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\").fit(X_train, y_train)\n",
    "    print(\"Dummy majority baseline accuracy:\", dummy.score(X_test, y_test))\n",
    "\n",
    "    # --- Train models ----------------------------------------------------\n",
    "    rf, svm, ada = train_models(X_train, y_train)\n",
    "\n",
    "    # --- Evaluate --------------------------------------------------------\n",
    "    rf_pred = evaluate(\"Random Forest\", rf, X_test, y_test)\n",
    "    svm_pred = evaluate(\"Linear SVM\", svm, X_test, y_test)\n",
    "    ada_pred = evaluate(\"AdaBoost\", ada, X_test, y_test)\n",
    "\n",
    "    # --- Agreement -------------------------------------------------------\n",
    "    print(\"\\n=== Prediction agreement on test set ===\")\n",
    "    print(\"RF vs SVM :\", agreement(rf_pred, svm_pred))\n",
    "    print(\"RF vs Ada :\", agreement(rf_pred, ada_pred))\n",
    "    print(\"SVM vs Ada:\", agreement(svm_pred, ada_pred))\n",
    "\n",
    "\n",
    "    # --- Top features ----------------------------------------------------\n",
    "    print(\"\\n=== Top features per model ===\")\n",
    "    print(\"Random Forest:\")\n",
    "    top_features(rf, feat_names)\n",
    "    print(\"\\nLinear SVM:\")\n",
    "    top_features(svm, feat_names)\n",
    "    print(\"\\nAdaBoost:\")\n",
    "    top_features(ada, feat_names)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdec6bb-559d-491c-ae80-4a0bb58e4ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
